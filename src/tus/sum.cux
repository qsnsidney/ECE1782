#include <stdio.h>
#include <stdlib.h>
#include <sys/time.h>
#include <cublas_v2.h>

double getTimeStamp() 
{
    struct timeval  tv ; gettimeofday( &tv, NULL ) ;
    return (double) tv.tv_usec/1000000 + tv.tv_sec ;
}

void printMatrix(float* M, char* name, int r)
{
    int i;
    printf("%s\n", name);
    for (i = 0; i < r; i++)
    {
        printf("%f ", M[i]);
    }
    printf("\n=============================\n");
}

template <unsigned int blockSize>
__device__ void warpReduce(volatile float *sdata, unsigned int tid, int n) {
    if ((blockSize >= 64) && (tid + 32 < n)) sdata[tid] += sdata[tid + 32];
    if ((blockSize >= 32) && (tid + 16 < n)) sdata[tid] += sdata[tid + 16];
    if ((blockSize >= 16) && (tid + 8 < n)) sdata[tid] += sdata[tid + 8];
    if ((blockSize >= 8) && (tid + 4 < n)) sdata[tid] += sdata[tid + 4];
    if ((blockSize >= 4) && (tid + 2 < n)) sdata[tid] += sdata[tid + 2];
    if ((blockSize >= 2) && (tid + 1 < n)) sdata[tid] += sdata[tid + 1];
}

template <unsigned int blockSize>
__global__ void reduce2(float *g_idata, float *g_odata, int n) {
    extern __shared__ float sdata[];
    unsigned int tid = threadIdx.x;
    unsigned int i = blockIdx.x*(blockSize*2) + tid;
    unsigned int gridSize = blockSize*2*gridDim.x;
    sdata[tid] = 0;

    while (i < n) { 
        sdata[tid] += g_idata[i] + g_idata[i+blockSize]; 
        i += gridSize; 
    }
    __syncthreads();

    if (blockSize >= 512) { if ((tid < 256) && (tid + 256 < n)) { sdata[tid] += sdata[tid + 256]; } __syncthreads(); }
    if (blockSize >= 256) { if ((tid < 128) && (tid + 128 < n)) { sdata[tid] += sdata[tid + 128]; } __syncthreads(); }
    if (blockSize >= 128) { if ((tid < 64) && (tid + 64 < n)) { sdata[tid] += sdata[tid + 64]; } __syncthreads(); }

    if (tid < 32) warpReduce<blockSize>(sdata, tid, n);
    if (tid == 0) 
    {
        g_odata[blockIdx.x] = sdata[0];
        //printf("block %d has data %f\n", blockIdx.x, sdata[0]);
    }
}

__global__ void reduce1(float *g_idata, float *g_odata, int n, int uid) {
    extern __shared__ float sdata[];
    // each thread loads one element from global to shared mem
    int tid = threadIdx.x;
    int i = blockIdx.x*blockDim.x + threadIdx.x;

    // 33 -> 2 has an issue

    //sdata[tid] = (i < n) ? g_idata[i] : 0;
    if (i < n)
    {
        sdata[tid] = g_idata[i];
        //if (uid > 0) printf("%d - input: g_idata[%d] = %f\n", uid, i, g_idata[i]);
    }
    __syncthreads();

    // do reduction in shared mem
    for (int s=1; s < blockDim.x; s *= 2) 
    { 
        // s: stride
        if ((tid % (2*s) == 0) && (i + s < n)) {
            // only tids divisible by s*2 partake
            sdata[tid] += sdata[tid + s];
        }
        __syncthreads();
    }
    // write result for this block to global mem
    if (tid == 0) 
    {
        g_odata[blockIdx.x] = sdata[0];
        //printf("%d - output: block %d has data %f\n", uid, blockIdx.x, sdata[0]);
    }
}

int main(int argc, char *argv[])
{
    if (argc != 3 )
    {
        printf("Error: Wrong number of arguments :(\n");
        exit(1);
    }

    int r = atoi(argv[1]);
    int op = atoi(argv[2]);

    if (r<0)
    {
        printf("Error: Arguments not greater than 0\n");
        exit(1);
    }
    int i;
    double total_GPU_time=0, CPU_GPU_transfer_time=0, kernel_time=0, GPU_CPU_transfer_time=0, Z_value=0;
    int num = r*sizeof(float);

    // Dynamically allocate and initialize required matrices
    float* h_X, *h_dZ;
    cudaError_t err;
    err = cudaHostAlloc( (void **) &h_X, num, 0 ) ;
    if( err != cudaSuccess )
    {
        printf( "Error: %s in %s at line %d\n", cudaGetErrorString( err ), __FILE__, __LINE__ );
        exit( EXIT_FAILURE );
    }
    err = cudaHostAlloc( (void **) &h_dZ, num*sizeof(float), 0 ) ;
    if( err != cudaSuccess )
    {
        printf( "Error: %s in %s at line %d\n", cudaGetErrorString( err ), __FILE__, __LINE__ );
        exit( EXIT_FAILURE );
    }
    float h_hZ = 0;

    for (i = 0; i < r; i++)
    {
        h_X[i] = 1;
    }

    //printMatrix(h_Y, "h_Y", r, c);

    // CPU reference
    for (i = 0; i < r; i++)
    {
        h_hZ += h_X[i];
    }

    printf("h_hZ: %f\n", h_hZ);

    // CPU to GPU transfer
    float *d_X, *d_Z1, *d_Z2;
    err = cudaMalloc( (void **) &d_X, num ) ;
    if( err != cudaSuccess )
    {
        printf( "Error: %s in %s at line %d\n", cudaGetErrorString( err ), __FILE__, __LINE__ );
        exit( EXIT_FAILURE );
    }

    double cg_transfer_start = getTimeStamp();
    err = cudaMemcpy( d_X, h_X, num, cudaMemcpyHostToDevice ) ;
    if( err != cudaSuccess )
    {
        printf( "Error: %s in %s at line %d\n", cudaGetErrorString( err ), __FILE__, __LINE__ );
        exit( EXIT_FAILURE );
    }
    double cg_transfer_end = getTimeStamp();

    dim3 block = 32;
    int blockNum = (r + block.x-1)/block.x;
    err = cudaMalloc( (void **) &d_Z1, blockNum*sizeof(float) ) ;
    if( err != cudaSuccess )
    {
        printf( "Error: %s in %s at line %d\n", cudaGetErrorString( err ), __FILE__, __LINE__ );
        exit( EXIT_FAILURE );
    }
    err = cudaMalloc( (void **) &d_Z2, blockNum*sizeof(float) ) ;
    if( err != cudaSuccess )
    {
        printf( "Error: %s in %s at line %d\n", cudaGetErrorString( err ), __FILE__, __LINE__ );
        exit( EXIT_FAILURE );
    }

    cublasStatus_t stat;
    cublasHandle_t handle;
    float* h_dz = (float*)malloc(sizeof(float));
    
    stat = cublasCreate(&handle);
    if (stat != CUBLAS_STATUS_SUCCESS) {
        printf ("CUBLAS initialization failed\n");
        return EXIT_FAILURE;
    }

    // Invoke kernel
    double kernel_start = getTimeStamp();
    stat = cublasSasum(handle, r, d_X, 1, h_dz);
    
    /*

    const int bs = 32;
    //printf("first blockNum: %d\n", blockNum);
    int count = 0, total = 0;
    if (op == 2)
    {
        reduce2<bs><<<blockNum, block, r*sizeof(float)>>>( d_X, d_Z1, r ) ;
    }
    else 
    {
        reduce1<<<blockNum, block, r*sizeof(float)>>>( d_X, d_Z1, r, count );
    }

    // 33 block -> 2 block -> 1 block
    // 32 block -> 1 block
    while (blockNum >= 1)
    {
        count += 1;
        total = blockNum;
        //printf("%d blockNum: %d\n", count, blockNum);
        blockNum = (blockNum + block.x-1)/block.x;
        if (op == 2)
        {
            reduce2<bs><<<blockNum, block, blockNum*sizeof(float)>>>( d_Z1, d_Z2, total );
        }
        else 
        {
            reduce1<<<blockNum, block, blockNum*sizeof(float)>>>( d_Z1, d_Z2, total, count );
        }

        float *tmp;
        tmp = d_Z1;
        d_Z1 = d_Z2;
        d_Z2 = tmp;

        if (blockNum == 1) break;
    }
    */

    cudaDeviceSynchronize();
    double kernel_end = getTimeStamp();
    printf("cublas result: %f\n", *h_dz);

    /*
    // GPU to CPU transfer
    double gc_transfer_start = getTimeStamp();

    err = cudaMemcpy( h_dZ, d_Z1, blockNum*sizeof(float), cudaMemcpyDeviceToHost );
    if( err != cudaSuccess )
    {
        printf( "Error: %s in %s at line %d\n", cudaGetErrorString( err ), __FILE__, __LINE__ );
        exit( EXIT_FAILURE );
    }
    double gc_transfer_end = getTimeStamp();

    printMatrix(h_dZ, "h_dZ", blockNum);

    // GPU & CPU result comparison
    if (h_hZ != *h_dZ)
    {
        printf("Error: GPU result is different from CPU - kernel has errors!\n");
    }
    */

    //Report: <total_GPU_time> <CPU_GPU_transfer_time> <kernel_time> <GPU_CPU_transfer_time> <Z-value>
    //CPU_GPU_transfer_time = cg_transfer_end - cg_transfer_start;
    kernel_time = kernel_end - kernel_start;
    //GPU_CPU_transfer_time = gc_transfer_end - gc_transfer_start;
    //total_GPU_time = gc_transfer_end - cg_transfer_start;
    //printf("<%f> <%f> <%f> <%f> <%f>\n", total_GPU_time, CPU_GPU_transfer_time, kernel_time, GPU_CPU_transfer_time, Z_value);
    printf("kernel time: %f\n", kernel_time);

    // Free resources
    cublasDestroy(handle);
    free(h_dz);
    cudaFree(d_X);
    cudaFree(d_Z1);
    cudaFreeHost(h_X);
    cudaFreeHost(h_dZ);
    cudaDeviceReset();
}

